{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSDS458_Assignment_03_ExperimentA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNID9TZ0XQkWWL6Y+7aCBlv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xixilili/MSDS_458_Public/blob/master/MSDS458_Assignment_03_Experiment_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Package"
      ],
      "metadata": {
        "id": "1aCwgEKag1yI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "metadata": {
        "id": "r_VF1bTsisyU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from packaging import version\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "RJqMG9yqg5BX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Process Data"
      ],
      "metadata": {
        "id": "4Nn84T_qePrI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyu_R81id9n4",
        "outputId": "5e725bbe-30a9-44b3-f03b-02d89eca7619"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-18 03:25:06.871843: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "I0218 03:25:06.872176 140347919812480 download_and_prepare.py:200] Running download_and_prepare for dataset(s):\n",
            "ag_news_subset\n",
            "I0218 03:25:07.190204 140347919812480 dataset_info.py:434] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: ag_news_subset/1.0.0\n",
            "I0218 03:25:07.545532 140347919812480 dataset_info.py:361] Load dataset info from /tmp/tmphk2seuqctfds\n",
            "I0218 03:25:07.550262 140347919812480 download_and_prepare.py:138] download_and_prepare for dataset ag_news_subset/1.0.0...\n",
            "I0218 03:25:07.550886 140347919812480 dataset_builder.py:357] Generating dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset ag_news_subset/1.0.0 (download: 11.24 MiB, generated: 35.79 MiB, total: 47.03 MiB) to /root/tensorflow_datasets/ag_news_subset/1.0.0...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0218 03:25:08.105404 140347919812480 download_manager.py:476] Downloading https://drive.google.com/uc?export=download&id=0Bz8a_Dbh9QhbUDNpeUdjb0wxRms into /root/tensorflow_datasets/downloads/ucexport_download_id_0Bz8a_Dbh9QhbUDNpeUdjb0wxj4g1umFAV8OV-uDwxSJR0LdxO_k1jxMuFWwAfNX9jos.tmp.f8bcbe86fe2a44e6894ee5cbbcc47d81...\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:   0% 0/11 [00:24<?, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:   9% 1/11 [00:24<04:05, 24.55s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  18% 2/11 [00:24<03:40, 24.55s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  27% 3/11 [00:24<03:16, 24.55s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  36% 4/11 [00:24<02:51, 24.55s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  45% 5/11 [00:24<02:27, 24.55s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  55% 6/11 [00:24<02:02, 24.55s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  64% 7/11 [00:24<01:38, 24.55s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:24, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  73% 8/11 [00:24<00:06,  2.25s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  82% 9/11 [00:24<00:04,  2.25s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...:  91% 10/11 [00:24<00:02,  2.25s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:24<?, ? url/s]\n",
            "Dl Size...: 100% 11/11 [00:24<00:00,  2.25s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:24<00:00, 24.70s/ url]\n",
            "Dl Size...: 100% 11/11 [00:24<00:00,  2.25s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:24<00:00, 24.70s/ url]\n",
            "Dl Size...: 100% 11/11 [00:24<00:00,  2.25s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...:   0% 0/1 [00:24<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:25<00:00, 24.70s/ url]\n",
            "Dl Size...: 100% 11/11 [00:25<00:00,  2.25s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 100% 1/1 [00:25<00:00, 25.08s/ file]\u001b[A\u001b[A\n",
            "Extraction completed...: 100% 1/1 [00:25<00:00, 25.08s/ file]\n",
            "\n",
            "Dl Size...: 100% 11/11 [00:25<00:00,  2.28s/ MiB]\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:25<00:00, 25.08s/ url]\n",
            "I0218 03:25:33.186199 140347919812480 dataset_builder.py:970] Generating split train\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteO81RKL/ag_news_subset-train.tfrecord\n",
            " 65% 77882/120000 [00:00<00:00, 274772.26 examples/s]I0218 03:25:58.351482 140347919812480 tfrecords_writer.py:226] Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteO81RKL/ag_news_subset-train.tfrecord. Shard lengths: [120000]\n",
            "I0218 03:25:58.367220 140347919812480 dataset_builder.py:970] Generating split test\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteO81RKL/ag_news_subset-test.tfrecord\n",
            "  0% 0/7600 [00:00<?, ? examples/s]I0218 03:25:59.926614 140347919812480 tfrecords_writer.py:226] Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteO81RKL/ag_news_subset-test.tfrecord. Shard lengths: [7600]\n",
            "I0218 03:25:59.929224 140347919812480 dataset_builder.py:412] Skipping computing stats for mode ComputeStatsMode.SKIP.\n",
            "\u001b[1mDataset ag_news_subset downloaded and prepared to /root/tensorflow_datasets/ag_news_subset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "\u001b[1mname: \"ag_news_subset\"\n",
            "description: \"AG is a collection of more than 1 million news articles.\\nNews articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity.\\nComeToMyHead is an academic news search engine which has been running since July, 2004.\\nThe dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc),\\ninformation retrieval (ranking, search, etc), xml, data compression, data streaming,\\nand any other non-commercial activity.\\nFor more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\\n\\nThe AG\\'s news topic classification dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the dataset above.\\nIt is used as a text classification benchmark in the following paper:\\nXiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\\n\\nThe AG\\'s news topic classification dataset is constructed by choosing 4 largest classes from the original corpus.\\nEach class contains 30,000 training samples and 1,900 testing samples.\\nThe total number of training samples is 120,000 and testing 7,600.\"\n",
            "citation: \"@misc{zhang2015characterlevel,\\n    title={Character-level Convolutional Networks for Text Classification},\\n    author={Xiang Zhang and Junbo Zhao and Yann LeCun},\\n    year={2015},\\n    eprint={1509.01626},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.LG}\\n}\"\n",
            "location {\n",
            "  urls: \"https://arxiv.org/abs/1509.01626\"\n",
            "}\n",
            "splits {\n",
            "  name: \"test\"\n",
            "  shard_lengths: 7600\n",
            "  num_bytes: 2226751\n",
            "}\n",
            "splits {\n",
            "  name: \"train\"\n",
            "  shard_lengths: 120000\n",
            "  num_bytes: 35301386\n",
            "}\n",
            "supervised_keys {\n",
            "  input: \"description\"\n",
            "  output: \"label\"\n",
            "}\n",
            "version: \"1.0.0\"\n",
            "download_size: 11784327\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# register  ag_news_subset so that tfds.load doesn't generate a checksum (mismatch) error\n",
        "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=ag_news_subset\n",
        "\n",
        "# Example Approaches to Split Data Set\n",
        "# dataset, info = tfds.load('ag_news_subset', with_info=True,  split=['train[:]','test[:1000]', 'test[1000:]'],\n",
        "dataset, info = tfds.load('ag_news_subset', with_info=True,  split=['train[:95%]','train[95%:]', 'test[:]'],\n",
        "# dataset, info = tfds.load('ag_news_subset', with_info=True,  split=['train[:114000]','train[114000:]', 'test[:]'],\n",
        "                          as_supervised=True)\n",
        "train_dataset, validation_dataset, test_dataset = dataset\n",
        "# train_dataset, test_dataset = dataset['train'],dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "jGZlYD3R1rag"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "B6HRSW6d1qku"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "kqyQvZUFeUAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoder(VOCAB_SIZE):\n",
        "  encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n",
        "  encoder.adapt(train_dataset.map(lambda text, label: text))\n",
        "  return encoder"
      ],
      "metadata": {
        "id": "A-Bsb3k3eMLA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Model"
      ],
      "metadata": {
        "id": "shH2_ALqeTgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def creat_model(encoder):\n",
        "  model = tf.keras.Sequential([\n",
        "                              encoder\n",
        "                              ,tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary())\n",
        "                              ,output_dim=64\n",
        "                                # Use masking to handle the variable sequence lengths\n",
        "                              ,mask_zero=True)\n",
        "                              ,tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))\n",
        "                              ,tf.keras.layers.Dense(64, activation='relu')\n",
        "                              ,tf.keras.layers.Dense(4,activation='softmax')   # num_classes = 4\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "vEoPYv-Wenik"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile, Train Model"
      ],
      "metadata": {
        "id": "ogNw-Hdge25x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def namestr(obj, namespace):\n",
        "  for name in namespace:\n",
        "    if namespace[name] is obj:\n",
        "      return name"
      ],
      "metadata": {
        "id": "MTnJI_UEuXsl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "\n",
        "def compile_train_model(model, epoch):\n",
        "  #compile model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(1e-4)\n",
        "              ,loss=tf.keras.losses.SparseCategoricalCrossentropy() # if we set from_logits=True we don not have specify a softmax activation function in the last layer\n",
        "              ,metrics=['accuracy'])\n",
        "\n",
        "  start_datetime = dt.datetime.now()\n",
        "\n",
        "  #train model  \n",
        "  history = model.fit(train_dataset\n",
        "                    ,epochs = epoch\n",
        "                    ,validation_data=validation_dataset\n",
        "                    ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]\n",
        "                    )\n",
        "\n",
        "\n",
        "  #evaluate model\n",
        "  loss, accuracy = model.evaluate(test_dataset)\n",
        "  print('test set accuracy: ', accuracy * 100)\n",
        "\n",
        "  runtime = (dt.datetime.now() - start_datetime).total_seconds()\n",
        "\n",
        "  #training and validation performance metrix\n",
        "  history_dict = history.history\n",
        "  history_df=pd.DataFrame(history_dict)\n",
        "\n",
        "  #loss and accuracy for training and validation data\n",
        "  losses = history.history['loss']\n",
        "  accs = history.history['accuracy']\n",
        "  val_losses = history.history['val_loss']\n",
        "  val_accs = history.history['val_accuracy']\n",
        "  epochs = len(losses)\n",
        "\n",
        "  result = history_df.tail(1)\n",
        "  result['test_loss'] = loss\n",
        "  result['test_accuracy'] = accuracy\n",
        "  result['process_time'] = runtime\n",
        "  result['epochs_setting'] = epoch  \n",
        "  result['epochs_actual'] = epochs    \n",
        "\n",
        "  plt.figure(figsize=(16, 4))\n",
        "  for i, metrics in enumerate(zip([losses, accs], [val_losses, val_accs], ['Loss', 'Accuracy'])):\n",
        "      plt.subplot(1, 2, i + 1)\n",
        "      plt.plot(range(epochs), metrics[0], label='Training {}'.format(metrics[2]))\n",
        "      plt.plot(range(epochs), metrics[1], label='Validation {}'.format(metrics[2]))\n",
        "      plt.legend()\n",
        "      plt.title('{0} with {1} epochs'.format(namestr(model, globals()), epoch))   \n",
        "  plt.show()  \n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "YmShiKBnfZGW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore Vocab"
      ],
      "metadata": {
        "id": "nRU1LsKDuhXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_vocab(train_dataset,encoder):\n",
        "  doc_sizes = []\n",
        "  corpus = []\n",
        "  for example, _ in train_dataset.as_numpy_iterator():\n",
        "    enc_example = encoder(example)\n",
        "    doc_sizes.append(len(enc_example))\n",
        "    corpus+=list(enc_example.numpy())\n",
        "  return  corpus, doc_sizes"
      ],
      "metadata": {
        "id": "SyebLb6Qo5ja"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment A a\n",
        "(a) Vocabulary Size: Tweak the vocabulary size, at least 3 levels, eg. vocab size of 1000, 2000, 3000. This way, we can get insights whether the performance metric is non linearly related to the vocab size."
      ],
      "metadata": {
        "id": "v7Bm_fDthKnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocab 1000"
      ],
      "metadata": {
        "id": "IrnBPmCj2dtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "EPOCH_SIZE = 200\n",
        "encoder1000 = get_encoder(VOCAB_SIZE)"
      ],
      "metadata": {
        "id": "hkBui_ADhQ1F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus1000, doc_sizes1000 = explore_vocab(train_dataset,encoder1000)"
      ],
      "metadata": {
        "id": "KxtNKiq2pm7J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab1000 = np.array(encoder1000.get_vocabulary())\n",
        "num_vocab_words_in_corpus =len(vocab1000)\n",
        "\n",
        "num_words =len(corpus1000)\n",
        "num_articles =len(doc_sizes1000)\n",
        "min_token_in_a_article = min(doc_sizes1000)\n",
        "max_token_in_a_article = max(doc_sizes1000)  \n",
        "\n",
        "print(num_vocab_words_in_corpus)\n",
        "print(num_words)\n",
        "print(num_articles)\n",
        "print(min_token_in_a_article)\n",
        "print(max_token_in_a_article)\n",
        "\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.hist(doc_sizes1000, bins=20,range = (0,120))\n",
        "plt.xlabel(\"Tokens Per Document\")\n",
        "plt.ylabel(\"Number of AG News Articles\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "ttHkXBZ0oO7C",
        "outputId": "05049cc5-72ad-449d-9aa2-60eb2af44ffc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "114000\n",
            "1782\n",
            "16\n",
            "64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RNN1000 = creat_model(encoder1000)\n",
        "result1000 = compile_train_model(RNN1000, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxAGGboviGqu",
        "outputId": "b4d18c63-8167-4211-f684-a1990a1dfb68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1782/1782 [==============================] - 241s 130ms/step - loss: 0.7139 - accuracy: 0.7356 - val_loss: 0.4944 - val_accuracy: 0.8272\n",
            "Epoch 2/200\n",
            "1782/1782 [==============================] - 233s 131ms/step - loss: 0.4718 - accuracy: 0.8311 - val_loss: 0.4777 - val_accuracy: 0.8290\n",
            "Epoch 3/200\n",
            "1782/1782 [==============================] - 226s 127ms/step - loss: 0.4499 - accuracy: 0.8375 - val_loss: 0.4464 - val_accuracy: 0.8435\n",
            "Epoch 4/200\n",
            "1782/1782 [==============================] - 234s 131ms/step - loss: 0.4402 - accuracy: 0.8409 - val_loss: 0.4415 - val_accuracy: 0.8462\n",
            "Epoch 5/200\n",
            "1782/1782 [==============================] - 227s 127ms/step - loss: 0.4323 - accuracy: 0.8435 - val_loss: 0.4360 - val_accuracy: 0.8477\n",
            "Epoch 6/200\n",
            "1782/1782 [==============================] - 244s 137ms/step - loss: 0.4236 - accuracy: 0.8462 - val_loss: 0.4225 - val_accuracy: 0.8497\n",
            "Epoch 7/200\n",
            "1782/1782 [==============================] - 273s 153ms/step - loss: 0.4089 - accuracy: 0.8527 - val_loss: 0.4230 - val_accuracy: 0.8483\n",
            "Epoch 8/200\n",
            "1782/1782 [==============================] - 241s 135ms/step - loss: 0.3950 - accuracy: 0.8571 - val_loss: 0.3930 - val_accuracy: 0.8642\n",
            "Epoch 9/200\n",
            "1782/1782 [==============================] - 234s 131ms/step - loss: 0.3840 - accuracy: 0.8616 - val_loss: 0.3904 - val_accuracy: 0.8633\n",
            "Epoch 10/200\n",
            "1782/1782 [==============================] - 234s 131ms/step - loss: 0.3770 - accuracy: 0.8638 - val_loss: 0.3883 - val_accuracy: 0.8660\n",
            "Epoch 11/200\n",
            "1782/1782 [==============================] - 236s 132ms/step - loss: 0.3713 - accuracy: 0.8652 - val_loss: 0.3812 - val_accuracy: 0.8647\n",
            "Epoch 12/200\n",
            "1782/1782 [==============================] - 238s 133ms/step - loss: 0.3671 - accuracy: 0.8663 - val_loss: 0.3801 - val_accuracy: 0.8665\n",
            "Epoch 13/200\n",
            "1782/1782 [==============================] - 264s 148ms/step - loss: 0.3637 - accuracy: 0.8676 - val_loss: 0.3759 - val_accuracy: 0.8680\n",
            "Epoch 14/200\n",
            " 849/1782 [=============>................] - ETA: 1:58 - loss: 0.3569 - accuracy: 0.8696"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result1000['vocab_size'] = VOCAB_SIZE \n",
        "result1000['num_words'] = num_words \n",
        "result1000['num_articles'] = num_articles\n",
        "result1000['min_token_in_a_article'] = min_token_in_a_article \n",
        "result1000['max_token_in_a_article'] = max_token_in_a_article "
      ],
      "metadata": {
        "id": "csZM1XnyoP-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assignment_result_table = result1000\n",
        "new_col = ['RNN with 1000 vocab size']   \n",
        "assignment_result_table.insert(loc=0, column='Model', value=new_col)\n",
        "assignment_result_table"
      ],
      "metadata": {
        "id": "UFGVytCA3ZYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocab 2000"
      ],
      "metadata": {
        "id": "U1hD3wrA2ibc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 2000\n",
        "EPOCH_SIZE = 200\n",
        "encoder2000 = get_encoder(VOCAB_SIZE)"
      ],
      "metadata": {
        "id": "bqzQUUu42keW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus2000, doc_sizes2000 = explore_vocab(train_dataset,encoder2000)"
      ],
      "metadata": {
        "id": "RJu3uXcT2q6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab2000 = np.array(encoder2000.get_vocabulary())\n",
        "num_vocab_words_in_corpus =len(vocab2000)\n",
        "\n",
        "num_words =len(corpus2000)\n",
        "num_articles =len(doc_sizes2000)\n",
        "min_token_in_a_article = min(doc_sizes2000)\n",
        "max_token_in_a_article = max(doc_sizes2000)  \n",
        "\n",
        "print(num_vocab_words_in_corpus)\n",
        "print(num_words)\n",
        "print(num_articles)\n",
        "print(min_token_in_a_article)\n",
        "print(max_token_in_a_article)\n",
        "\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.hist(doc_sizes2000, bins=20,range = (0,120))\n",
        "plt.xlabel(\"Tokens Per Document\")\n",
        "plt.ylabel(\"Number of AG News Articles\");"
      ],
      "metadata": {
        "id": "gMMPUM3I21ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN2000 = creat_model(encoder2000)\n",
        "result2000 = compile_train_model(RNN2000, 200)"
      ],
      "metadata": {
        "id": "pz6JuXTA3DpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result2000['vocab_size'] = VOCAB_SIZE \n",
        "result2000['num_words'] = num_words \n",
        "result2000['num_articles'] = num_articles\n",
        "result2000['min_token_in_a_article'] = min_token_in_a_article \n",
        "result2000['max_token_in_a_article'] = max_token_in_a_article \n",
        "new_col = ['RNN with 2000 vocab size']   \n",
        "result2000.insert(loc=0, column='Model', value=new_col)"
      ],
      "metadata": {
        "id": "h4CHwO8w4Hdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assignment_result_table = assignment_result_table.append(result2000, ignore_index = True)\n",
        "assignment_result_table"
      ],
      "metadata": {
        "id": "FLDko_bK4Jhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocab 3000"
      ],
      "metadata": {
        "id": "qUv8AcS74_79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 3000\n",
        "EPOCH_SIZE = 200\n",
        "encoder3000 = get_encoder(VOCAB_SIZE)"
      ],
      "metadata": {
        "id": "rFFc5N_15Ewo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus3000, doc_sizes3000 = explore_vocab(train_dataset,encoder3000)"
      ],
      "metadata": {
        "id": "fTmgjVIO5IYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab3000 = np.array(encoder3000.get_vocabulary())\n",
        "num_vocab_words_in_corpus =len(vocab3000)\n",
        "\n",
        "num_words =len(corpus3000)\n",
        "num_articles =len(doc_sizes3000)\n",
        "min_token_in_a_article = min(doc_sizes3000)\n",
        "max_token_in_a_article = max(doc_sizes3000)  \n",
        "\n",
        "print(num_vocab_words_in_corpus)\n",
        "print(num_words)\n",
        "print(num_articles)\n",
        "print(min_token_in_a_article)\n",
        "print(max_token_in_a_article)\n",
        "\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.hist(doc_sizes3000, bins=20,range = (0,120))\n",
        "plt.xlabel(\"Tokens Per Document\")\n",
        "plt.ylabel(\"Number of AG News Articles\");"
      ],
      "metadata": {
        "id": "MU_v0Cge5Q7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RNN3000 = creat_model(encoder3000)\n",
        "result3000 = compile_train_model(RNN3000, 200)"
      ],
      "metadata": {
        "id": "-4_tel-95ZE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result3000['vocab_size'] = VOCAB_SIZE \n",
        "result3000['num_words'] = num_words \n",
        "result3000['num_articles'] = num_articles\n",
        "result3000['min_token_in_a_article'] = min_token_in_a_article \n",
        "result3000['max_token_in_a_article'] = max_token_in_a_article \n",
        "new_col = ['RNN with 3000 vocab size']   \n",
        "result3000.insert(loc=0, column='Model', value=new_col)"
      ],
      "metadata": {
        "id": "VkbLUvR65daK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assignment_result_table = assignment_result_table.append(result3000, ignore_index = True)\n",
        "assignment_result_table"
      ],
      "metadata": {
        "id": "j406UjTd5ilE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Test Accuracy by Vocab Size"
      ],
      "metadata": {
        "id": "WzdCFWUW7Tph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x= assignment_result_table['vocab_size']\n",
        "y= assignment_result_table['test_accuracy']\n",
        "plt.plot(x,y)"
      ],
      "metadata": {
        "id": "1X4ZpceQ7TJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment A b\n",
        "(b) Editing the Vocabulary: Try unedited most frequent words, VERSUS edit the list by deleting the most frequent words such as article, ‘the’, ‘a’, etc."
      ],
      "metadata": {
        "id": "E0sdKXmK7cT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deleting the most frequent words from vocab"
      ],
      "metadata": {
        "id": "Fy5jhVdT9Faa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = stopwords.words('english')"
      ],
      "metadata": {
        "id": "QPr7HjZB9Fvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab1000[:20]"
      ],
      "metadata": {
        "id": "KWdVmWmB7IFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_vocab1000= []\n",
        "for w in vocab:\n",
        "    if w not in stopwords:\n",
        "        filtered_vocab1000.append(w)"
      ],
      "metadata": {
        "id": "bGsn6pg9DHt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_vocab1000[:20]"
      ],
      "metadata": {
        "id": "jFJQfWleDtjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QFg0UG8e9Dez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_tokenize(txt):\n",
        "    tokens = re.findall(\"[\\w']+\", txt)\n",
        "    return tokens\n",
        "df.Summary=df.Summary.apply(word_tokenize)\n",
        "\n",
        "def remove_stopwords(lst):\n",
        "    stop=stopwords\n",
        "    new_lst=[]\n",
        "    for i in lst:\n",
        "        if i not in stop:\n",
        "            new_lst.append(i)\n",
        "    return new_lst"
      ],
      "metadata": {
        "id": "3XQfZp6T7Kk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords=set(stopwords.words('english'))\n",
        "\n",
        "data =['I really love writing journals','The mat is very comfortable and I will buy it again likes','The mousepad is smooth']\n",
        "\n",
        "def remove_stopwords(data):\n",
        "    output_array=[]\n",
        "    for sentence in data:\n",
        "        temp_list=[]\n",
        "        for word in sentence.split():\n",
        "            if word.lower() not in stopwords:\n",
        "                temp_list.append(word)\n",
        "        output_array.append(' '.join(temp_list))\n",
        "    return output_array\n",
        "\n",
        "output=remove_stopwords(data)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "vgxQBacC81OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment A c\n",
        "(c) Output sequence length: Use the default VERSUS set it to a fixed number"
      ],
      "metadata": {
        "id": "mvNHiJVk8-2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output sequence length"
      ],
      "metadata": {
        "id": "ZiMD1a2n9WIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoder_with_seq_length(VOCAB_SIZE, SEQ_LENGTH):\n",
        "  encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE, output_sequence_length=SEQ_LENGTH)\n",
        "  encoder.adapt(train_dataset.map(lambda text, label: text))\n",
        "  return encoder"
      ],
      "metadata": {
        "id": "P2uV8KAw9K_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 1000\n",
        "EPOCH_SIZE = 200\n",
        "SEQ_LENGTH = 50 \n",
        "encoder1000_50 = get_encoder_with_seq_length(VOCAB_SIZE, SEQ_LENGTH)"
      ],
      "metadata": {
        "id": "u2B4edun-gFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus1000_50, doc_sizes1000_50 = explore_vocab(train_dataset,encoder1000_50)"
      ],
      "metadata": {
        "id": "QujSio0h_DpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab1000_50 = np.array(encoder1000_50.get_vocabulary())\n",
        "num_vocab_words_in_corpus =len(vocab1000_50)\n",
        "\n",
        "num_words =len(corpus1000_50)\n",
        "num_articles =len(doc_sizes1000_50)\n",
        "min_token_in_a_article = min(doc_sizes1000_50)\n",
        "max_token_in_a_article = max(doc_sizes1000_50)  \n",
        "\n",
        "print(num_vocab_words_in_corpus)\n",
        "print(num_words)\n",
        "print(num_articles)\n",
        "print(min_token_in_a_article)\n",
        "print(max_token_in_a_article)\n",
        "\n",
        "plt.figure(figsize=(15,9))\n",
        "plt.hist(doc_sizes1000_50, bins=20,range = (0,120))\n",
        "plt.xlabel(\"Tokens Per Document\")\n",
        "plt.ylabel(\"Number of AG News Articles\")"
      ],
      "metadata": {
        "id": "qSXBZ1iF_JQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "RNN1000_50 = creat_model(encoder1000_50)\n",
        "result1000_50 = compile_train_model(RNN1000_50, 200)"
      ],
      "metadata": {
        "id": "-WePjs9wAsS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1000_50['vocab_size'] = VOCAB_SIZE \n",
        "result1000_50['num_words'] = num_words \n",
        "result1000_50['num_articles'] = num_articles\n",
        "result1000_50['min_token_in_a_article'] = min_token_in_a_article \n",
        "result1000_50['max_token_in_a_article'] = max_token_in_a_article \n",
        "new_col = ['RNN with 1000 vocab size 50 output sequence length']   \n",
        "result1000_50.insert(loc=0, column='Model', value=new_col)"
      ],
      "metadata": {
        "id": "39O-eWVcAv68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assignment_result_table = assignment_result_table.append(result1000_50, ignore_index = True)\n",
        "assignment_result_table"
      ],
      "metadata": {
        "id": "ggfq1HyaAy-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save data"
      ],
      "metadata": {
        "id": "UeZjVGEg5_2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assignment_result_table.to_pickle(\"resultsAa.pkl\") "
      ],
      "metadata": {
        "id": "NamBFDFZ59Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prev_results_df = pd.read_pickle('resultsAa.pkl')\n",
        "#assignment_result_table = prev_results_df.append(assignment_result_table,ignore_index=True)\n",
        "#assignment_result_table"
      ],
      "metadata": {
        "id": "91BlRjfM58PA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}